{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4liTBggY6Idx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"The code will run on GPU.\")\n",
        "else:\n",
        "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CuMRS5B6KFN",
        "outputId": "128cc32d-8724-4eac-8dcf-e2eb447f2774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The code will run on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "XFXQoFXs6X5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc5a34a-6d1a-4b0b-f77c-f8a1b8b29298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-pXYyVxDhSK",
        "outputId": "6ced0d3c-4038-4a66-a8cf-cae1e1229e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1614671043843.gdoc\n",
            " 31228\n",
            " 31228_Arunima_Garg_Documents.pdf\n",
            " 31228_Arunima_Garg.pdf\n",
            " 31228_Arunima_Internship_Report.docx\n",
            " 41148_LP3_Assignments\n",
            " 41245_Maitreyee_NLP_A3.ipynb\n",
            " 6.cpp.gdoc\n",
            "'ACM group.jpeg'\n",
            " Arunima_Garg_Aadhar_Card.pdf\n",
            "'Arunima Garg Internship Letter (1).pdf'\n",
            "'Arunima Garg Internship Letter (2).pdf'\n",
            "'Arunima Garg Internship Letter (3).pdf'\n",
            "'Arunima Garg Internship Letter.pdf'\n",
            "'Arunima Garg Profile_41228.pdf'\n",
            "'Arunima Garg Profile.pdf'\n",
            "'Arunima_Garg_resume (1).pdf'\n",
            "'ArunimaGarg_Resume (1).pdf'\n",
            "'Arunima_Garg_resume (2).pdf'\n",
            "'ArunimaGarg_Resume (2).pdf'\n",
            "'Arunima_Garg_resume (3).pdf'\n",
            "'ArunimaGarg_Resume (3).pdf'\n",
            " Arunima_Garg_resume_final.pdf\n",
            " Arunima_Garg_resume.pdf\n",
            " ArunimaGarg_Resume.pdf\n",
            " ArunimaGarg.zip\n",
            "'Arunima Photo.jpg'\n",
            "'Arunima Web Developor.pdf'\n",
            " Australia.gslides\n",
            " Be_8\n",
            " binary_tree.cpp\n",
            " C2K20106556_ArunimaGarg_Documents.pdf\n",
            "'C2K20106556_ArunimaGarg_Resume (1).pdf'\n",
            " C2K20106556_ArunimaGarg_resume.pdf\n",
            " C2K20106556_ArunimaGarg_Resume.pdf\n",
            "'CIS-ITSM Certification'\n",
            "'Class TT.docx'\n",
            "'Colab Notebooks'\n",
            "'Differential Equation (TN).gdoc'\n",
            " dsal2_prxatice.cpp\n",
            " dsal3.cpp\n",
            " dsal3.d\n",
            " dsal_a2.cpp\n",
            " DSC_0052.JPG\n",
            " DSC_0536.JPG\n",
            "'Dubai Trip.gdoc'\n",
            "'Employee certificate.gslides'\n",
            "'fifth (1).asm'\n",
            " fifth.asm\n",
            " fifth.o\n",
            "'Getting started.pdf'\n",
            " graph_1.cpp\n",
            " graph_2.cpp\n",
            " hash_telephone.cpp\n",
            " hotdog_nothotdog\n",
            " large.asm\n",
            " large.o\n",
            " lec1Notes.gdoc\n",
            " lec2Notes.gdoc\n",
            " lp3-main.zip\n",
            " m_tbt.cpp\n",
            "'New Document(2) 01-Aug-2020 12-45-02.gdoc'\n",
            "'No ppo.docx'\n",
            " Parabola_New_Assignment_Ddr\n",
            " Parabola_New_Assignment_Ddr.gdoc\n",
            "'Photo album.gslides'\n",
            " print.asm\n",
            " queue_using_template.h\n",
            " Report_BE.docx\n",
            "'research work.gdoc'\n",
            " sign.asm\n",
            " stack_using_template.h\n",
            " Symtab.java\n",
            " tbt.cpp\n",
            "'Tweet Scheduler.gsheet'\n",
            "'Untitled presentation.gslides'\n",
            "'WhatsApp Image 2021-09-20 at 5.14.11 PM.jpeg'\n",
            " word.asm\n",
            " word.o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
        "    def __init__(self, train, transform, data_path='/content/gdrive/MyDrive/hotdog_nothotdog'):\n",
        "        'Initialization'\n",
        "        self.transform = transform\n",
        "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
        "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
        "        image_classes.sort()\n",
        "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
        "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path)\n",
        "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
        "        y = self.name_to_label[c]\n",
        "        X = self.transform(image)\n",
        "        return X, y\n"
      ],
      "metadata": {
        "id": "w_cbuRNrDulK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "\n",
        "size = 128\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size, scale=(0.8, 1.0)),   # random crop & resize\n",
        "    transforms.RandomHorizontalFlip(),                      # flip 50% of the time\n",
        "    transforms.RandomRotation(15),                          # rotate between -15Â° and +15Â°\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# âœ… Test data (no augmentation, only resize)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((size, size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# -------------------\n",
        "# Datasets & Loaders\n",
        "# -------------------\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=train_transform, data_path='/content/gdrive/MyDrive/hotdog_nothotdog')\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=3)\n",
        "\n",
        "testset = Hotdog_NotHotdog(train=False, transform=test_transform, data_path='/content/gdrive/MyDrive/hotdog_nothotdog')\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=3)"
      ],
      "metadata": {
        "id": "4tbDO0P2EA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images, labels = next(iter(train_loader))\n",
        "# plt.figure(figsize=(20,10))\n",
        "\n",
        "# for i in range(21):\n",
        "#     plt.subplot(5,7,i+1)\n",
        "#     plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))\n",
        "#     plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
        "#     plt.axis('off')\n"
      ],
      "metadata": {
        "id": "t9wYgm0BFBQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -----------------\n",
        "# Model definition\n",
        "# -----------------\n",
        "class HotdogCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HotdogCNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.6)   # increased dropout\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(256, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.gap(x)                # GAP reduces to (B, 256, 1, 1)\n",
        "        x = torch.flatten(x, 1)        # flatten to (B, 256)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aw2p4RaGIEc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "# Training setup\n",
        "# -----------------\n",
        "model = HotdogCNN().to(device)\n",
        "\n",
        "# âœ… Label smoothing\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "# âœ… Use adaptive LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "num_epochs = 30\n",
        "patience = 5   # early stopping patience\n",
        "best_loss = float(\"inf\")\n",
        "patience_counter = 0"
      ],
      "metadata": {
        "id": "qRMeJnSLr76x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# -----------------\n",
        "for epoch in range(num_epochs):\n",
        "    # ---- Training ----\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "\n",
        "    # ---- Evaluation ----\n",
        "    model.eval()\n",
        "    test_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = 100 * correct / total\n",
        "\n",
        "    # ---- Learning rate update ----\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    # ---- Print stats ----\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    # ---- Early stopping ----\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_hotdog_model.pth\")  # save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered ðŸš¨\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "h4bz0_3OXtAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ceb05cb-6e17-404e-8d36-7a49cce09745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30] Train Loss: 0.6322, Train Acc: 66.88% | Test Loss: 0.7715, Test Acc: 48.07%\n",
            "Epoch [2/30] Train Loss: 0.5642, Train Acc: 74.40% | Test Loss: 0.7279, Test Acc: 63.64%\n",
            "Epoch [3/30] Train Loss: 0.5422, Train Acc: 76.89% | Test Loss: 0.6280, Test Acc: 68.26%\n",
            "Epoch [4/30] Train Loss: 0.5293, Train Acc: 77.58% | Test Loss: 0.5303, Test Acc: 77.12%\n",
            "Epoch [5/30] Train Loss: 0.5004, Train Acc: 80.41% | Test Loss: 0.5417, Test Acc: 77.82%\n",
            "Epoch [6/30] Train Loss: 0.5024, Train Acc: 80.80% | Test Loss: 0.5237, Test Acc: 77.82%\n",
            "Epoch [7/30] Train Loss: 0.4988, Train Acc: 80.26% | Test Loss: 0.5250, Test Acc: 77.12%\n",
            "Epoch [8/30] Train Loss: 0.4891, Train Acc: 81.97% | Test Loss: 0.5185, Test Acc: 77.39%\n",
            "Epoch [9/30] Train Loss: 0.4958, Train Acc: 80.51% | Test Loss: 0.8341, Test Acc: 60.04%\n",
            "Epoch [10/30] Train Loss: 0.4955, Train Acc: 80.80% | Test Loss: 0.5031, Test Acc: 79.22%\n",
            "Epoch [11/30] Train Loss: 0.4819, Train Acc: 82.17% | Test Loss: 0.8913, Test Acc: 52.85%\n",
            "Epoch [12/30] Train Loss: 0.4639, Train Acc: 82.41% | Test Loss: 0.4876, Test Acc: 79.05%\n",
            "Epoch [13/30] Train Loss: 0.4716, Train Acc: 82.36% | Test Loss: 0.5028, Test Acc: 80.50%\n",
            "Epoch [14/30] Train Loss: 0.4602, Train Acc: 83.68% | Test Loss: 0.6860, Test Acc: 69.71%\n",
            "Epoch [15/30] Train Loss: 0.4693, Train Acc: 83.39% | Test Loss: 0.5101, Test Acc: 80.18%\n",
            "Epoch [16/30] Train Loss: 0.4459, Train Acc: 83.83% | Test Loss: 0.4679, Test Acc: 81.85%\n",
            "Epoch [17/30] Train Loss: 0.4399, Train Acc: 84.37% | Test Loss: 0.4834, Test Acc: 82.01%\n",
            "Epoch [18/30] Train Loss: 0.4344, Train Acc: 85.25% | Test Loss: 0.4543, Test Acc: 82.65%\n",
            "Epoch [19/30] Train Loss: 0.4350, Train Acc: 85.78% | Test Loss: 0.5445, Test Acc: 77.93%\n",
            "Epoch [20/30] Train Loss: 0.4319, Train Acc: 85.54% | Test Loss: 0.5464, Test Acc: 77.50%\n",
            "Epoch [21/30] Train Loss: 0.4205, Train Acc: 86.13% | Test Loss: 0.5533, Test Acc: 75.67%\n",
            "Epoch [22/30] Train Loss: 0.4163, Train Acc: 85.93% | Test Loss: 0.4576, Test Acc: 82.92%\n",
            "Epoch [23/30] Train Loss: 0.4097, Train Acc: 87.01% | Test Loss: 0.4766, Test Acc: 82.76%\n",
            "Early stopping triggered ðŸš¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cpNxeNGIsE4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}